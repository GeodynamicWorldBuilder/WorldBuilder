{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plate Reconstruction and Conversion to World Builder JSON\n",
    "----------------------------------------------------------\n",
    "This script reconstructs tectonic plates at a specified geological time using either remote \n",
    "plate model data or local files. It extracts key geological features such as continents, \n",
    "ridges, and trenches, and saves them in GeoJSON format. Additionally, it converts these \n",
    "GeoJSON files into World Builder-compatible JSON files to facilitate further geodynamic \n",
    "modeling and visualization.\n",
    "\n",
    "**Workflow:**\n",
    "1. The script loads plate reconstruction data (from remote repository or local files).\n",
    "2. It extracts and saves key geological features as GeoJSON files.\n",
    "3. The extracted GeoJSON files are then converted into World Builder-compatible JSON.\n",
    "4. A final JSON output is saved with all processed features directly usable by GWB.\n",
    "\n",
    "**Usage Instructions:**\n",
    "- Configure `reconstruction_time` to set the geological age.\n",
    "- Set `use_local_files` to `True` to use local data, otherwise, it will fetch from the remote repository.\n",
    "- Ensure required dependencies are installed: `pygplates`, `gplately`, `matplotlib`, `cartopy`.\n",
    "\n",
    "**Outputs:**\n",
    "- GeoJSON files for each feature type (e.g., continents, ridges, trenches).\n",
    "- A final World Builder JSON file saved in `contrib/gplate/data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import json\n",
    "# Set path if necessary\n",
    "# sys.path.append('/your/path/pygplates_0.36.0_py310_Darwin-arm64')  # Update path if different\n",
    "import pygplates\n",
    "\n",
    "import gplately\n",
    "from plate_model_manager import PlateModelManager\n",
    "\n",
    "# User-defined parameters\n",
    "reconstruction_time = 400  # Ma\n",
    "plate_reconstruction_model = \"Merdith2021\" #Muller2019 #Clennett2020\n",
    "use_local_files = False  # Set to True to use local files instead of online repo\n",
    "\n",
    "#for use of local files use \n",
    "input_directory = \"./path/to/local_plate_reconstruction/\"\n",
    "\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \"./data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load plate model data based on user choice\n",
    "if use_local_files:\n",
    "\n",
    "    # Load rotation model\n",
    "    rotation_filenames = glob.glob(os.path.join(input_directory, '*.rot'))\n",
    "    rotation_model = pygplates.RotationModel(rotation_filenames)\n",
    "\n",
    "    # Load topology features\n",
    "    topology_filenames = glob.glob(os.path.join(input_directory, '*.gpml'))\n",
    "    topology_features = pygplates.FeatureCollection()\n",
    "    for topology_filename in topology_filenames:\n",
    "        if \"Inactive\" not in topology_filename:\n",
    "            topology_features.add(pygplates.FeatureCollection(topology_filename))\n",
    "\n",
    "    # Load static polygons\n",
    "    \n",
    "    static_polygon_file = os.path.join(input_directory, \"StaticGeometries/StaticPolygons/polygons.shp\")\n",
    "    static_polygons = pygplates.FeatureCollection(static_polygon_file)\n",
    "\n",
    "\n",
    "    ## Example of use of local file \n",
    "    #  Additonnal information : https://gplates.github.io/gplately/v1.3.0/02-PlateReconstructions.html\n",
    "\n",
    "    ## For testing download the following data set :\n",
    "    ## https://www.earthbyte.org/webdav/ftp/Data_Collections/Muller_etal_2019_Tectonics/Muller_etal_2019_PlateMotionModel/\n",
    "\n",
    "    ## For exampe case uncomment the following lines \n",
    "    # coastlines = input_directory+\"StaticGeometries/Coastlines/Global_coastlines_2019_v1_low_res.shp\"\n",
    "    # continents = input_directory+\"StaticGeometries/ContinentalPolygons/Global_EarthByte_GPlates_PresentDay_ContinentalPolygons_2019_v1.shp\"\n",
    "    # COBs = input_directory+\"StaticGeometries/AgeGridInput/Global_EarthByte_GeeK07_IsoCOB_2019_v2.gpml\"\n",
    "    # input_directory = \"./local_repository_where_downloaded/Muller_etal_2019_PlateMotionModel_v2.0_Tectonics/\"\n",
    "    # static_polygon_file = input_directory+\"StaticGeometries/StaticPolygons/Global_EarthByte_GPlates_PresentDay_StaticPlatePolygons_2019_v1.shp\"\n",
    "        \n",
    "else:\n",
    "    # Load model data from remote repository\n",
    "    pm_manager = PlateModelManager()\n",
    "    model_data = pm_manager.get_model(plate_reconstruction_model, data_dir=\"plate-model-repo\")\n",
    "    rotation_model = model_data.get_rotation_model()\n",
    "    topology_features = model_data.get_topologies()\n",
    "    static_polygons = model_data.get_static_polygons()\n",
    "\n",
    "    # Load coastline and continent data\n",
    "    coastlines = model_data.get_layer('Coastlines')\n",
    "    continents = model_data.get_layer('ContinentalPolygons')\n",
    "\n",
    "# Create plate reconstruction model\n",
    "model = gplately.PlateReconstruction(rotation_model, topology_features, static_polygons)\n",
    "\n",
    "# Initialize PlotTopologies with the plate reconstruction model and data layers\n",
    "gplot = gplately.PlotTopologies(model, coastlines=coastlines, continents=continents)\n",
    "\n",
    "# Set reconstruction time\n",
    "gplot.time = reconstruction_time  # Ma\n",
    "\n",
    "# Define the default features to extract\n",
    "default_features = {\n",
    "    \"continents\": gplot.get_continents,\n",
    "    \"ridges_and_transforms\": gplot.get_ridges_and_transforms,\n",
    "    \"trenches\": gplot.get_trenches\n",
    "}\n",
    "\n",
    "# Extract and save the default features\n",
    "for feature, func in default_features.items():\n",
    "    try:\n",
    "        geo_data = func()\n",
    "        if geo_data is None or geo_data.empty:\n",
    "            print(f\"Feature '{feature}' is not available for this plate reconstruction model.\")\n",
    "        else:\n",
    "            file_path = os.path.join(output_dir, f\"{feature}.geojson\")\n",
    "            geo_data.to_file(file_path, driver=\"GeoJSON\")\n",
    "            print(f\"Feature '{feature}' saved as {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting '{feature}': {e}\")\n",
    "\n",
    "# Plot the data\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "ax1 = fig.add_subplot(111, projection=ccrs.Mollweide(190))\n",
    "\n",
    "gplot.plot_continents(ax1, facecolor='0.8')\n",
    "gplot.plot_coastlines(ax1, color='0.5')\n",
    "gplot.plot_ridges_and_transforms(ax1, color='red')\n",
    "gplot.plot_trenches(ax1, color='k')\n",
    "gplot.plot_subduction_teeth(ax1, color='k')\n",
    "\n",
    "# Simulate an age grid (replace with actual data if available)\n",
    "try:\n",
    "    agegrid = model.get_age_grid()\n",
    "    im = gplot.plot_grid(ax1, agegrid.data, cmap='YlGnBu', vmin=0, vmax=200)\n",
    "    fig.colorbar(im, orientation='horizontal', shrink=0.4, pad=0.05, label='Age (Ma)')\n",
    "except AttributeError:\n",
    "    print(\"Age grid not available for this model.\")\n",
    "\n",
    "# Add title with time and model information\n",
    "title_text = f\"Plate Reconstruction - {plate_reconstruction_model} at {reconstruction_time} Ma\"\n",
    "ax1.set_title(title_text, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Save the plot\n",
    "plot_file_path = os.path.join(output_dir, f\"{plate_reconstruction_model}_{reconstruction_time}Ma_reconstruction.png\")\n",
    "plt.savefig(plot_file_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Plate reconstruction plot saved as {plot_file_path}\")\n",
    "\n",
    "# Show the plot (optional)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON to World Builder JSON Conversion\n",
    "\n",
    "This script converts GeoJSON files containing geological features into a World Builder-compatible JSON format for geodynamic modeling, assigning appropriate properties such as depth, thermal, and compositional characteristics. \n",
    "\n",
    "Plate boundaries, such as ridges and trenches, are converted into **Fault** features, which include properties like dip angle, segment length, and composition variations. Continents are represented as **Continental Plate** features, characterized by uniform composition and a defined maximum depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_geojson_to_worldbuilder_json(geojson_file, default_max_depth=350e3,default_min_depth = -1000.0):\n",
    "    \"\"\"\n",
    "    Converts a GeoJSON file to a JSON dictionary formatted for use in World Builder.\n",
    "    \n",
    "    Args:\n",
    "        geojson_file (str): Path to the input GeoJSON file.\n",
    "        default_max_depth (float): Default maximum depth for all plates.\n",
    "    \n",
    "    Returns:\n",
    "        list: Converted JSON features formatted for World Builder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(geojson_file, 'r') as f:\n",
    "            geojson_data = json.load(f)\n",
    "\n",
    "        features = []\n",
    "        continental_counter = 1\n",
    "        fault_counter = 1\n",
    "        trench_counter = 1\n",
    "\n",
    "        for feature in geojson_data.get('features', []):\n",
    "            geometry_type = feature.get('geometry', {}).get('type')\n",
    "            coordinates = feature.get('geometry', {}).get('coordinates', [])\n",
    "\n",
    "            if geometry_type == \"Polygon\":\n",
    "                # Handle continent polygon correctly\n",
    "                processed_coords = coordinates[0]  # Outer ring\n",
    "\n",
    "                feature_data = {\n",
    "                    \"model\": \"continental plate\",\n",
    "                    \"name\": f'continental_plate_{continental_counter}',\n",
    "                    \"max depth\": default_max_depth,\n",
    "                    \"coordinates\": processed_coords,\n",
    "                    \"temperature models\": [{\"model\": \"linear\", \"max depth\": default_max_depth}],\n",
    "                    \"composition models\": [\n",
    "                        {\n",
    "                            \"model\": \"uniform\",\n",
    "                            \"compositions\": [0],\n",
    "                            \"max depth\": default_max_depth\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                features.append(feature_data)\n",
    "                continental_counter += 1\n",
    "\n",
    "            elif geometry_type == \"LineString\":\n",
    "                # Handle ridges and trenches differently based on filename\n",
    "                feature_name = os.path.basename(geojson_file).lower()\n",
    "                composition_number = 2 if \"trench\" in feature_name else 1\n",
    "\n",
    "                feature_data = {\n",
    "                    \"model\": \"fault\",\n",
    "                    \"name\": f'{\"trench\" if \"trench\" in feature_name else \"fault\"}_{fault_counter}',\n",
    "                    \"coordinates\": coordinates,\n",
    "                    \"dip point\": [0, 1],\n",
    "                    \"min depth\": default_min_depth,\n",
    "                    \"max depth\": default_max_depth,\n",
    "                    \"segments\": [{\"length\": 300000.0, \"thickness\": [100000.0], \"angle\": [90, 90]}],\n",
    "                    \"composition models\": [{\"model\": \"smooth\", \"compositions\": [composition_number], \"side distance fault center\": 50000.0}]\n",
    "                }\n",
    "                features.append(feature_data)\n",
    "                fault_counter += 1\n",
    "\n",
    "            elif geometry_type == \"MultiLineString\":\n",
    "                for segment in coordinates:\n",
    "                    feature_name = os.path.basename(geojson_file).lower()\n",
    "                    composition_number = 2 if \"trench\" in feature_name else 1\n",
    "\n",
    "                    feature_data = {\n",
    "                        \"model\": \"fault\",\n",
    "                        \"name\": f'{\"trench\" if \"trench\" in feature_name else \"fault\"}_{trench_counter}',\n",
    "                        \"coordinates\": segment,\n",
    "                        \"dip point\": [0, 1],\n",
    "                        \"min depth\": default_min_depth,\n",
    "                        \"max depth\": default_max_depth,\n",
    "                        \"segments\": [{\"length\": 300000.0, \"thickness\": [100000.0], \"angle\": [90, 90]}],\n",
    "                        \"composition models\": [{\"model\": \"smooth\", \"compositions\": [composition_number], \"side distance fault center\": 50000.0}]\n",
    "                    }\n",
    "                    features.append(feature_data)\n",
    "                    trench_counter += 1\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {geojson_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define input and output directories\n",
    "data_dir = \"contrib/gplates/data/\"\n",
    "output_file = os.path.join(data_dir, \"world_builder_model.json\")\n",
    "\n",
    "# Process GeoJSON files\n",
    "geojson_files = [f for f in os.listdir(data_dir) if f.endswith('.geojson')]\n",
    "all_features = []\n",
    "\n",
    "for geojson_file in geojson_files:\n",
    "    file_path = os.path.join(data_dir, geojson_file)\n",
    "    features = convert_geojson_to_worldbuilder_json(file_path)\n",
    "    if features:\n",
    "        all_features.extend(features)\n",
    "\n",
    "# Combine all features into a World Builder JSON structure\n",
    "output_data = {\n",
    "    \"version\": \"1.1\",\n",
    "    \"interpolation\": \"continuous monotone spline\",\n",
    "    \"coordinate system\": {\n",
    "        \"model\": \"spherical\",\n",
    "        \"depth method\": \"starting point\"\n",
    "    },\n",
    "    \"features\": all_features\n",
    "}\n",
    "\n",
    "# Save combined JSON in the same data directory\n",
    "with open(output_file, 'w') as out_f:\n",
    "    json.dump(output_data, out_f, indent=4)\n",
    "\n",
    "print(f\"Conversion successful! Output saved to {output_file}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of grid file content to run worldbuilder \n",
    "```\n",
    "# output variables\n",
    "grid_type = sphere\n",
    "dim = 3\n",
    "compositions = 1\n",
    "\n",
    "# domain of the grid\n",
    "x_max = 180\n",
    "x_min = -180\n",
    "y_max = 90\n",
    "y_min = -90\n",
    "z_min = 6000000\n",
    "z_max = 6371000\n",
    "\n",
    "# grid properties\n",
    "n_cell_x = 60  # Set this to match n_cell_y\n",
    "n_cell_y = 60  # Ensures the grid is square for sphere\n",
    "n_cell_z = 5\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extra_postprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
